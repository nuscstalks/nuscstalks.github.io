---
layout: post
author: gim_hee
---
Teaching Machines to See Our 3D World

## Abstract
The ability to perceive and understand the world in 3D is undoubtedly one of the most important competencies for autonomous machines such as selfdriving cars, drones, etc, to co-exist with humans and other living and nonliving entities. Despite the enormous efforts on computer vision in the past decade, most of the works are largely focused on 2D understanding and thus are not directly useful for autonomous machines to operate in our 3D world. In this talk, I will discuss my works on giving machines the ability to see our 3D world. I will first talk about some of my earlier works that are focused on solving the challenges in geometry for camera pose estimation and largescale 3D reconstruction using the conventional pinhole cameras, and other less conventional cameras such as the generalized and rolling shutter cameras. I will then talk about my recent works that focus on semantic 3D scene understanding using machine learning techniques. These works include 3D point clouds processing, 3D object detection, 3D semantic labeling, 6D object pose estimation, 3D human and animal pose estimation and prediction, 3D neural scene representation, etc. 



## Biodata
Dr Gim Hee Lee is currently an Associate Professor at the Department of
Computer Science at the National University of Singapore (NUS), where he heads the Computer Vision and Robotic Perception (CVRP) Laboratory. He was a researcher at Mitsubishi Electric Research Laboratories (MERL), USA. Prior to MERL, he did his PhD in Computer Science at ETH Zurich, Switzerland. He received his B.Eng with first class honors and M.Eng degrees from the Department of Mechanical Engineering at NUS. His research interests are in Computer Vision, Machine Learning and Robotics. 
