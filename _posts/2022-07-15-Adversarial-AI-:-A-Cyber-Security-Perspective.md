---
layout: post
author: elovici
---
Adversarial AI: A Cyber Security Perspective

## Abstract
In recent years, machine learning algorithms and, more specifically, deep learning algorithms have been widely used in many fields, including cyber security. However, machine learning systems are vulnerable to adversarial attacks, and this limits the application of machine learning, particularly in dynamic, adversarial environments, such as the cyber security domain where actual adversaries exist. This talk will shed light on the latest research on adversarial attacks against security solutions based on machine learning techniques. It will illuminate the risks they pose while illustrating the feasibility of launching adversarial attacks on security systems in general and cyber security systems in particular. The talk will also provide an overview of attacks on advanced driver assistance systems (ADASs), which are widely used by EVs like Tesla; surveillance systems, which are widely used at airports to detect suspects that appear on a blacklist; and malware classifiers, which are embedded in endpoint EDR and intrusion detection systems widely deployed at large organizations. 

## Biodata
Alexander Golovnev is an Assistant Professor at Georgetown University. Prior to this, he was a Rabin postdoctoral fellow at Harvard University, a postdoctoral fellow at Columbia University, and a Research Scientist at Yahoo Research. He received his Ph.D. from the Courant Institute of Mathematical Sciences at New York University. Alexander's research interests lie broadly in computational complexity, algorithms, learning theory, cryptography, and pseudorandomness, with a focus on proving lower bounds for various computational models.
